{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from src.controllers.time_series_hls import HLS\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from src.controllers.sentinel_ import Sentinel2Processor\n",
    "from src.controllers.geometry import GeoDataFrameProcessor\n",
    "from src.controllers.eras import PrecipitationTemperatureRadiationData\n",
    "\n",
    "# Conecta ao Google Earth Engine\n",
    "ee.Authenticate()\n",
    "ee.Initialize()\n",
    "\n",
    "# Datas de análise\n",
    "start_date = '2023-01-01'\n",
    "end_date = (datetime.today() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "\n",
    "#Paht polygons\n",
    "path = r\"C:\\Users\\ander\\OneDrive\\Área de Trabalho\\msu\\bases\\base\\fields_tests.geojson\"\n",
    "\n",
    "vegetation_index = 'ndvi'\n",
    "\n",
    "#Order NDVI\n",
    "order_ndvi = 30\n",
    "\n",
    "window_size = 7\n",
    "\n",
    "poly_order = 3\n",
    "\n",
    "product = 's2'\n",
    "\n",
    "#Read geometry file\n",
    "processador = GeoDataFrameProcessor(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>satellite</th>\n",
       "      <th>timestamps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>T14TPP_20230105T171150</td>\n",
       "      <td>-0.054202</td>\n",
       "      <td>landsat</td>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>T14TPP_20230106T170536</td>\n",
       "      <td>-0.054073</td>\n",
       "      <td>landsat</td>\n",
       "      <td>2023-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.055007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.055942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.056876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.271187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.263209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.247253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>T14TPP_20241107T171128</td>\n",
       "      <td>0.239275</td>\n",
       "      <td>landsat</td>\n",
       "      <td>2024-11-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>673 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                      id      ndvi satellite timestamps\n",
       "0   2023-01-05  T14TPP_20230105T171150 -0.054202   landsat 2023-01-05\n",
       "1   2023-01-06  T14TPP_20230106T170536 -0.054073   landsat 2023-01-06\n",
       "2   2023-01-07                     NaN -0.055007       NaN 2023-01-07\n",
       "3   2023-01-08                     NaN -0.055942       NaN 2023-01-08\n",
       "4   2023-01-09                     NaN -0.056876       NaN 2023-01-09\n",
       "..         ...                     ...       ...       ...        ...\n",
       "668 2024-11-03                     NaN  0.271187       NaN 2024-11-03\n",
       "669 2024-11-04                     NaN  0.263209       NaN 2024-11-04\n",
       "670 2024-11-05                     NaN  0.255231       NaN 2024-11-05\n",
       "671 2024-11-06                     NaN  0.247253       NaN 2024-11-06\n",
       "672 2024-11-07  T14TPP_20241107T171128  0.239275   landsat 2024-11-07\n",
       "\n",
       "[673 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_start_date(file_path, default_start_date, id):\n",
    "\n",
    "    file_ndvi = os.path.join(file_path, \"ndvi_df.csv\")\n",
    "    file_weather = os.path.join(file_path, \"ndvi_df.csv\")\n",
    "\n",
    "    if not file_ndvi:\n",
    "        df = pd.read_csv(file_ndvi)\n",
    "        default_start_date_ndvi = pd.to_datetime(df.sort_values(by='date')['date'].values[-1]).strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        default_start_date_ndvi = default_start_date\n",
    "\n",
    "    if not file_weather:\n",
    "        df = pd.read_csv(file_weather)\n",
    "        default_start_date_weather = pd.to_datetime(df.sort_values(by='date')['date'].values[-1]).strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        default_start_date_weather = default_start_date\n",
    "\n",
    "    return default_start_date_weather, default_start_date_ndvi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que processa cada polígono individualmente\n",
    "vertices, geometry = processador.extract_coordinates(10)\n",
    "\n",
    "if product == 'hls':\n",
    "    satellite = HLS(geometry, start_date, end_date)\n",
    "    ndvi_df = satellite.convert_to_dataframe()\n",
    "else:\n",
    "    s2 = Sentinel2Processor( start_date, end_date, geometry,  cloud_threshold=0)\n",
    "    ndvi_df = s2.get_filtered_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-11-12'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_poligono(id_poligono, product, start_date, end_date ):\n",
    "    # Função que processa cada polígono individualmente\n",
    "    vertices, geometry = processador.extrair_coordenadas(id_poligono)\n",
    "\n",
    "    if product == 'hls':\n",
    "        satellite = HLS(geometry, start_date, end_date)\n",
    "        ndvi_df = satellite.convert_to_dataframe()\n",
    "    else:\n",
    "        s2 = Sentinel2Processor( start_date, end_date, geometry,  cloud_threshold=35)\n",
    "        ndvi_df = s2.get_filtered_df()\n",
    "\n",
    "\n",
    "    # Obtenção de latitude e longitude (exemplo)\n",
    "    lat = geometry.getInfo()['coordinates'][0][0][1]\n",
    "    lon = geometry.getInfo()['coordinates'][0][0][0]\n",
    "\n",
    "    # Obtenção dos dados de precipitação, temperatura e radiação\n",
    "    data = PrecipitationTemperatureRadiationData(lat, lon, start_date, end_date)\n",
    "    df = data.get_dataframe()\n",
    "\n",
    "    # Criar diretório e salvar DataFrames\n",
    "    directory = f\"data_/{id_poligono}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Salvar DataFrames\n",
    "    ndvi_df.to_csv(os.path.join(directory, \"ndvi_df.csv\"), index=False)\n",
    "    df.to_csv(os.path.join(directory, \"precipitation_temperature_data.csv\"), index=False)\n",
    "\n",
    "    print(f\"Processamento concluído para id_poligono {id_poligono}\")\n",
    "\n",
    "for i in processador.index_polygons:\n",
    "    process_poligono(i, product, start_date, end_date)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-13 2024-11-07 2024-11-14\n",
      "Empty DataFrame\n",
      "Columns: [date, id, ndvi, satellite, timestamps]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 81\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Process all polygons\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m polygon_id \u001b[38;5;129;01min\u001b[39;00m geo_processor\u001b[38;5;241m.\u001b[39mindex_polygons:\n\u001b[1;32m---> 81\u001b[0m     \u001b[43mprocess_polygon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolygon_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2023-01-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 68\u001b[0m, in \u001b[0;36mprocess_polygon\u001b[1;34m(polygon_id, product, start_date, end_date)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Get precipitation, temperature, and radiation data\u001b[39;00m\n\u001b[0;32m     67\u001b[0m weather_data \u001b[38;5;241m=\u001b[39m PrecipitationTemperatureRadiationData(lat, lon, start_date_wather, end_date)\n\u001b[1;32m---> 68\u001b[0m weather_df \u001b[38;5;241m=\u001b[39m \u001b[43mweather_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(output_directory):\n\u001b[0;32m     71\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(output_directory)\n",
      "File \u001b[1;32mc:\\Users\\ander\\OneDrive\\Área de Trabalho\\msu\\bases\\src\\controllers\\eras.py:74\u001b[0m, in \u001b[0;36mPrecipitationTemperatureRadiationData.get_dataframe\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dataframe\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     73\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_data()\n\u001b[1;32m---> 74\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     75\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature_2m_max\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature_2m_max\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m273.15\u001b[39m)  \u001b[38;5;66;03m# Convert from Kelvin to Celsius\u001b[39;00m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m df\n",
      "File \u001b[1;32mc:\\Users\\ander\\anaconda3\\envs\\develoment_msu\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\ander\\anaconda3\\envs\\develoment_msu\\lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from src.controllers.time_series_hls import HLS\n",
    "from src.controllers.sentinel_ import Sentinel2Processor\n",
    "from src.controllers.geometry import GeoDataFrameProcessor\n",
    "from src.controllers.eras import PrecipitationTemperatureRadiationData\n",
    "\n",
    "# Connect to Google Earth Engine\n",
    "ee.Authenticate()\n",
    "ee.Initialize()\n",
    "\n",
    "# Analysis Dates\n",
    "end_date = (datetime.today() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "\n",
    "# Paths and Settings\n",
    "path_polygons = r\"C:\\Users\\ander\\OneDrive\\Área de Trabalho\\msu\\bases\\base\\fields_tests.geojson\"\n",
    "ndvi_order = 30\n",
    "window_size = 7\n",
    "poly_order = 3\n",
    "product = 's2'\n",
    "\n",
    "# Read geometry file\n",
    "geo_processor = GeoDataFrameProcessor(path_polygons)\n",
    "\n",
    "def update_start_date(file_path, default_start_date):\n",
    "    \"\"\"Update start date to the last available date in existing file.\"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'date' in df.columns:\n",
    "            last_date = pd.to_datetime(df['date']).max()\n",
    "            return (last_date + pd.Timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    return default_start_date\n",
    "\n",
    "def process_polygon(polygon_id, product, start_date, end_date):\n",
    "    \"\"\"Process each polygon individually.\"\"\"\n",
    "    vertices, geometry = geo_processor.extract_coordinates(polygon_id)\n",
    "\n",
    "        # Save DataFrames in structured directory\n",
    "    output_directory = f\".data_/{polygon_id}\"\n",
    "\n",
    "        # File paths for ndvi and weather data\n",
    "    ndvi_file = os.path.join(output_directory, \"ndvi_df.csv\")\n",
    "    weather_file = os.path.join(output_directory, \"precipitation_temperature_data.csv\")\n",
    "\n",
    "        # Adjust start date based on existing files\n",
    "    start_date_ndvi = update_start_date(ndvi_file, start_date)\n",
    "    start_date_wather = update_start_date(weather_file, start_date)\n",
    "\n",
    "    print(start_date_ndvi, start_date_wather, end_date)\n",
    "\n",
    "    # Satellite data processing\n",
    "    if product == 'hls':\n",
    "        satellite = HLS(geometry, start_date_ndvi, end_date)\n",
    "        ndvi_df = satellite.convert_to_dataframe()\n",
    "    else:\n",
    "        sentinel = Sentinel2Processor(start_date_ndvi, end_date, geometry, cloud_threshold=35)\n",
    "        ndvi_df = sentinel.get_filtered_df()\n",
    "\n",
    "    print(ndvi_df)\n",
    "\n",
    "    # Get latitude and longitude\n",
    "    lat, lon = geometry.getInfo()['coordinates'][0][0][1], geometry.getInfo()['coordinates'][0][0][0]\n",
    "\n",
    "    # Get precipitation, temperature, and radiation data\n",
    "    weather_data = PrecipitationTemperatureRadiationData(lat, lon, start_date_wather, end_date)\n",
    "    weather_df = weather_data.get_dataframe()\n",
    "\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # Save DataFrames\n",
    "    ndvi_df.to_csv(ndvi_file, index=False)\n",
    "    weather_df.to_csv(weather_file, index=False)\n",
    "\n",
    "    print(f\"Processing completed for polygon_id {polygon_id}\")\n",
    "\n",
    "# Process all polygons\n",
    "for polygon_id in geo_processor.index_polygons:\n",
    "    process_polygon(polygon_id, product, '2023-01-01', end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "develoment_msu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
