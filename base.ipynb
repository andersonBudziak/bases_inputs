{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from src.controllers.time_series_hls import HLS\n",
    "from src.controllers.sentinel import Sentinel2Processor\n",
    "from src.controllers.geometry import GeoDataFrameProcessor\n",
    "from src.controllers.eras import PrecipitationTemperatureRadiationData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate and initialize Google Earth Engine\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis dates\n",
    "START_DATE = '2023-01-01'\n",
    "END_DATE = (datetime.today() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "\n",
    "# Path to geometry file\n",
    "GEOMETRY_PATH = r\"C:\\Users\\ander\\OneDrive\\√Årea de Trabalho\\msu\\bases\\base\\fields_tests.geojson\"\n",
    "\n",
    "PRODUCT = 's2'\n",
    "\n",
    "# Initialize geometry processor\n",
    "geometry_processor = GeoDataFrameProcessor(GEOMETRY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_start_dates(file_path, default_start_date):\n",
    "    \"\"\"Update start dates for NDVI and weather data based on existing files.\"\"\"\n",
    "    ndvi_file = os.path.join(file_path, \"ndvi_data.csv\")\n",
    "    weather_file = os.path.join(file_path, \"weather_data.csv\")\n",
    "\n",
    "    if os.path.exists(ndvi_file):\n",
    "        ndvi_df = pd.read_csv(ndvi_file)\n",
    "        ndvi_start_date = pd.to_datetime(ndvi_df.sort_values(by='date')['date'].values[-1]).strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        ndvi_start_date = default_start_date\n",
    "\n",
    "    if os.path.exists(weather_file):\n",
    "        weather_df = pd.read_csv(weather_file)\n",
    "        weather_start_date = pd.to_datetime(weather_df.sort_values(by='date')['date'].values[-1]).strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        weather_start_date = default_start_date\n",
    "\n",
    "    return weather_start_date, ndvi_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_base_process(POLYGON_ID):\n",
    "\n",
    "    # Create directory to save DataFrames\n",
    "    directory = f\"data_/{POLYGON_ID}\"\n",
    "\n",
    "    # Process each individual polygon\n",
    "    vertices, geometry = geometry_processor.extract_coordinates(POLYGON_ID)\n",
    "\n",
    "    # Update start dates for NDVI and weather data\n",
    "    weather_start_date, ndvi_start_date = update_start_dates(directory, START_DATE)\n",
    "\n",
    "    # Get NDVI data based on product type\n",
    "    if PRODUCT == 'hls':\n",
    "        satellite = HLS(geometry, ndvi_start_date, END_DATE)\n",
    "        ndvi_df = satellite.convert_to_dataframe()\n",
    "    else:\n",
    "        s2_processor = Sentinel2Processor(ndvi_start_date, END_DATE, geometry, cloud_threshold=0)\n",
    "        ndvi_df = s2_processor.get_filtered_df()\n",
    "\n",
    "    # Extract latitude and longitude\n",
    "    latitude = geometry.getInfo()['coordinates'][0][0][1]\n",
    "    longitude = geometry.getInfo()['coordinates'][0][0][0]\n",
    "\n",
    "    # Get weather data: precipitation, temperature, and radiation\n",
    "    weather_data = PrecipitationTemperatureRadiationData(latitude, longitude, weather_start_date, END_DATE)\n",
    "    weather_df = weather_data.get_dataframe()\n",
    "\n",
    "    # Save or update NDVI and weather data\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        ndvi_df.to_csv(os.path.join(directory, \"ndvi_data.csv\"), index=False)\n",
    "        weather_df.to_csv(os.path.join(directory, \"weather_data.csv\"), index=False)\n",
    "    else:\n",
    "        # Update NDVI data\n",
    "        ndvi_history_df = pd.read_csv(os.path.join(directory, \"ndvi_data.csv\"))\n",
    "        ndvi_combined_df = pd.concat([ndvi_history_df, ndvi_df], ignore_index=True).drop_duplicates(subset=['date'])\n",
    "        ndvi_combined_df.to_csv(os.path.join(directory, \"ndvi_data.csv\"), index=False)\n",
    "\n",
    "        # Update weather data\n",
    "        weather_history_df = pd.read_csv(os.path.join(directory, \"weather_data.csv\"))\n",
    "        weather_combined_df = pd.concat([weather_history_df, weather_df], ignore_index=True).drop_duplicates(subset=['date'])\n",
    "        weather_combined_df.to_csv(os.path.join(directory, \"weather_data.csv\"), index=False)\n",
    "\n",
    "    print(f'Polygon {POLYGON_ID} finished.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for POLYGON_ID in geometry_processor.index_polygons:\n",
    "    data_base_process(POLYGON_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "develoment_msu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
